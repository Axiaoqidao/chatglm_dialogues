{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-12-20T06:15:28.036698Z","iopub.status.busy":"2023-12-20T06:15:28.036362Z","iopub.status.idle":"2023-12-20T06:19:25.161118Z","shell.execute_reply":"2023-12-20T06:19:25.160189Z","shell.execute_reply.started":"2023-12-20T06:15:28.036670Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==4.33.2\n","  Obtaining dependency information for transformers==4.33.2 from https://files.pythonhosted.org/packages/1a/06/3817f9bb923437ead9a794f0ac0d03b8b5e0478ab112db4c413dd37c09da/transformers-4.33.2-py3-none-any.whl.metadata\n","  Downloading transformers-4.33.2-py3-none-any.whl.metadata (119 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.9/119.9 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (3.12.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (0.17.3)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (1.24.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (2023.8.8)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (2.31.0)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.33.2)\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (0.4.0)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.33.2) (4.66.1)\n","Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2) (2023.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers==4.33.2) (4.5.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.33.2) (3.0.9)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.2) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.2) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.2) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.33.2) (2023.7.22)\n","Downloading transformers-4.33.2-py3-none-any.whl (7.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.14.1\n","    Uninstalling tokenizers-0.14.1:\n","      Successfully uninstalled tokenizers-0.14.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.35.0\n","    Uninstalling transformers-4.35.0:\n","      Successfully uninstalled transformers-4.35.0\n","Successfully installed tokenizers-0.13.3 transformers-4.33.2\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"966d9c59574342d8be49c2d63841e59f","version_major":2,"version_minor":0},"text/plain":["Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["你好👋！我是人工智能助手 ChatGLM2-6B，很高兴见到你，欢迎问我任何问题。\n","晚上睡不着可能是因为很多原因导致的，例如压力、忧虑、抑郁、失眠、不适应的作息时间等等。以下是一些有助于改善睡眠的建议：\n","\n","1. 晚上在睡觉前数绵羊或做一些轻松的伸展运动，有助于放松身体和大脑。\n","2. 睡前避免喝咖啡、茶、酒或含糖饮料，因为这些饮料会影响睡眠。\n","3. 睡前避免使用电子设备，例如手机、电脑或平板电脑，因为这些设备会发出蓝光，影响睡眠。\n","4. 睡前保持舒适的睡眠环境，例如调暗灯光、保持房间安静和凉爽、使用舒适的床垫和枕头等。\n","5. 睡前放松自己，例如通过阅读、听轻柔的音乐或洗个热水澡等方式。\n","6. 如果躺在床上无法入睡，不要继续躺在床上，可以去做一些轻松的活动，例如散步或阅读，然后再回到床上。\n","7. 如果问题持续存在，建议咨询医生或睡眠专家。\n"]}],"source":["!pip install transformers==4.33.2\n","\n","from transformers import AutoTokenizer, AutoModel\n","tokenizer = AutoTokenizer.from_pretrained(\"/kaggle/input/chatglm2/pytorch/6b/1\", trust_remote_code=True)\n","model = AutoModel.from_pretrained(\"/kaggle/input/chatglm2/pytorch/6b/1\", trust_remote_code=True).half().cuda()\n","model = model.eval()\n","response, history = model.chat(tokenizer, \"你好\", history=[])\n","print(response)\n","response, history = model.chat(tokenizer, \"晚上睡不着应该怎么办\", history=history)\n","print(response)\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:29:17.077298Z","iopub.status.busy":"2023-12-20T06:29:17.076373Z","iopub.status.idle":"2023-12-20T06:29:17.086092Z","shell.execute_reply":"2023-12-20T06:29:17.084968Z","shell.execute_reply.started":"2023-12-20T06:29:17.077256Z"},"trusted":true},"outputs":[],"source":["examples=[\n","(\"你需要进行标注小说，我会给你一段文字，你需要从中提取出对话，按照此格式{'role': '角色','dialogue': '对话','expression': '表情','mood':'情绪'}\",\n","'好的,请开始吧，我会认真的进行标注的'),\n","(\n","'''\n","他下意识放轻了脚步，不制造出明显的噪音。\n","刚登上二楼，他看见盥洗室的门突然打开，穿着旧布长裙的梅丽莎一副睡眼惺忪的模样出来。\n","“你回来了……”梅丽莎还有些迷糊地揉了揉眼睛。\n","克莱恩掩住嘴巴，打了个哈欠道：\n","“是的，我需要一个美好的梦境，午餐之前都不要叫醒我。”\n","梅丽莎“嗯”了一声，忽然想起什么似地说道：\n","“我和班森上午要去圣赛琳娜教堂做祈祷，参与弥撒，午餐可能会迟一点。”\n","''',\n","[\n","{\"role\": \"梅丽莎\", \"dialogue\": \"你回来了……\",'expression':'迷糊','mood':'平静'},\n","{\"role\": \"克莱恩\", \"dialogue\": \"是的，我需要一个美好的时梦境，午餐之前都不要叫醒我。\",'expression':'犯困','mood':'平静'},\n","{\"role\": \"梅丽莎\", \"dialogue\":\"我和班森上午要去圣赛琳娜教堂做祈祷，参与弥撒，午餐可能会迟一点。\",'expression':'迟疑','mood':'平静'}\n","]),\n","(\n","'''\n","“太感谢您了！‘愚者’先生您真是太慷慨了！”奥黛丽欣喜地回应道。\n","她为自己刚才想用金钱购买消息的庸俗忏悔了三秒。\n","克莱恩停止手指的敲动，语气平淡地描述道：\n","“第一个常识，非凡特性不灭定律，非凡特性不会毁灭，不会减少，只是从一个事物转移到另一个事物。”\n","我不知不觉竟然用上了队长的口吻……克莱恩的嘴角下意识就翘了起来。\n","''',\n","[\n","{\"role\": \"奥黛丽\", \"dialogue\": \"太感谢您了！‘愚者’先生您真是太慷慨了！\",'expression':'兴奋','mood':'感恩'},\n","{\"role\": \"克莱恩\", \"dialogue\": \"第一个常识，非凡特性不灭定律，非凡特性不会毁灭，不会减少，只是从一个事物转移到另一个事物。\",'expression':'装模作样','mood':'平静'},\n","])]"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:29:17.537616Z","iopub.status.busy":"2023-12-20T06:29:17.537205Z","iopub.status.idle":"2023-12-20T06:29:17.546396Z","shell.execute_reply":"2023-12-20T06:29:17.545326Z","shell.execute_reply.started":"2023-12-20T06:29:17.537583Z"},"trusted":true},"outputs":[],"source":["edit = [(\"请结合两个对话集的对话role，dialogue，expression，mood修改并选出最正确的一个输出严格按照对话集格式输出，不允许出现其他字\",'好的'),\n"," ( \"[{'role': '方源', 'dialogue': '乖乖地交出春秋蝉，给你个痛快！', 'expression': '冷漠', 'mood': '愤怒'}, {'role': '未知人物1', 'dialogue': '方老魔，你不要妄图反抗了，今日我们正道各大派联合起来，就是要踏破你的魔窟。', 'expression': '严厉', 'mood': '正义'}, {'role': '未知人物2', 'dialogue': '方源你个该死的魔头，你为了练成春秋蝉，杀了千万人的性命。你已经犯下了滔天的罪孽，罪无可恕，罄竹难书！', 'expression': '愤怒', 'mood': '正义'}, {'role': '未知人物3', 'dialogue': '魔头，三百年前你侮辱了我，夺走了我的清白之身，杀光我全家，诛了我的九族。从那刻起，我恨不得吃你肉，喝你的血！今天，我要让你生不如死！！', 'expression': '愤怒', 'mood': '复仇'}],[{'role': '某正道人士'', 'dialogue': '乖乖地交出春秋蝉，我给你个痛快！', 'expression': '冷漠', 'mood': '愤怒'}, {'role': '某正道人士', 'dialogue': '方老魔，你不要妄图反抗了，今日我们正道各大派联合起来，就是要踏破你的魔窟。这里早已经布下天罗地网，这次你必定身首异处！', 'expression': '愤怒', 'mood': '坚定'}, {'role': '方源', 'dialogue': '方源你个该死的魔头，你为了练成春秋蝉，杀了千万人的性命。你已经犯下了滔天的罪孽，罪无可恕，罄竹难书！', 'expression': '平静', 'mood': '愤怒'}, {'role': '某正道人士', 'dialogue': '魔头，三百年前你侮辱了我，夺走了我的清白之身，杀光我全家，诛了我的九族。从那刻起，我恨不得吃你肉，喝你的血！今天，我要让你生不如死！！', 'expression': '愤怒', 'mood': '复仇'}]\"\n",",\n","[{'role': '某正道人士', 'dialogue': '乖乖地交出春秋蝉，给你个痛快！', 'expression': '冷漠', 'mood': '愤怒'}, {'role': '某正道人士', 'dialogue': '方老魔，你不要妄图反抗了，今日我们正道各大派联合起来，就是要踏破你的魔窟。这里早已经布下天罗地网，这次你必定身首异处！', 'expression': '严厉', 'mood': '正义'}, {'role': '某正道人士', 'dialogue': '方源你个该死的魔头，你为了练成春秋蝉，杀了千万人的性命。你已经犯下了滔天的罪孽，罪无可恕，罄竹难书！', 'expression': '愤怒', 'mood': '正义'}, {'role': '某正道人士', 'dialogue': '魔头，三百年前你侮辱了我，夺走了我的清白之身，杀光我全家，诛了我的九族。从那刻起，我恨不得吃你肉，喝你的血！今天，我要让你生不如死！！', 'expression': '愤怒', 'mood': '复仇'}]),\n","(\"[{'role': '奥黛丽', 'dialogue': '太感谢您了！‘愚者’先生您真是太慷慨了！','expression':'兴奋','mood':'感恩'}],[{'role': '魔王', 'dialogue': '太感谢您了！‘愚者’先生您真是太慷慨了！','expression':'兴奋','mood':'感恩'}]\",\n"," \"[{'role': '奥黛丽', 'dialogue': '太感谢您了！‘愚者’先生您真是太慷慨了！','expression':'兴奋','mood':'感恩'}]\")]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:29:25.042356Z","iopub.status.busy":"2023-12-20T06:29:25.041731Z","iopub.status.idle":"2023-12-20T06:29:25.057980Z","shell.execute_reply":"2023-12-20T06:29:25.056842Z","shell.execute_reply.started":"2023-12-20T06:29:25.042310Z"},"trusted":true},"outputs":[],"source":["def split_text_into_paragraphs(text):\n","    # 根据换行符分割文本\n","    lines = text.split('\\n')\n","    paragraphs = []\n","    current_paragraph = ''\n","\n","    for line in lines:\n","        if len(current_paragraph) + len(line) <= 300:\n","            # 如果当前段落加上这一行不超过 300 个字符，则加入当前段落\n","            current_paragraph += line + '\\n'\n","        else:\n","            # 如果超过 300 个字符，则将当前段落加入段落列表，并重新开始一个新的段落\n","            paragraphs.append(current_paragraph)\n","            current_paragraph = line + '\\n'\n","\n","    # 将剩余的段落加入段落列表\n","    if current_paragraph:\n","        paragraphs.append(current_paragraph)\n","\n","    # 合并段落，直到每段至少有 100 个字符\n","    merged_paragraphs = []\n","    current_merged_paragraph = ''\n","    for paragraph in paragraphs:\n","        if len(current_merged_paragraph) + len(paragraph) <= 300:\n","            current_merged_paragraph += paragraph\n","        else:\n","            if len(current_merged_paragraph) >= 100:\n","                merged_paragraphs.append(current_merged_paragraph)\n","                current_merged_paragraph = paragraph\n","            else:\n","                current_merged_paragraph += paragraph\n","\n","    if current_merged_paragraph:\n","        merged_paragraphs.append(current_merged_paragraph)\n","\n","    return merged_paragraphs"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-12-20T06:29:30.691799Z","iopub.status.busy":"2023-12-20T06:29:30.691407Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Paragraph 1:\n","第一节：纵身亡魔心仍不悔\n","　　“方源，乖乖地交出春秋蝉，我给你个痛快！”\n","　　“方老魔，你不要妄图反抗了，今日我们正道各大派联合起来，就是要踏破你的魔窟。这里早已经布下天罗地网，这次你必定身首异处！”\n","　　“方源你个该死的魔头，你为了练成春秋蝉，杀了千万人的性命。你已经犯下了滔天的罪孽，罪无可恕，罄竹难书！”\n","　　“魔头，三百年前你侮辱了我，夺走了我的清白之身，杀光我全家，诛了我的九族。从那刻起，我恨不得吃你肉，喝你的血！今天，我要让你生不如死！！”\n","　　……\n","　　方源一身残破的碧绿大袍，披头散发，浑身浴血，环顾四周。\n","　　山风吹得血袍飘荡，如战旗般嚯嚯作响。\n","\n","\n","[{'role': '方源', 'dialogue': '第一节:纵身亡魔心仍不悔 “方源,乖乖地交出春秋蝉,我给你个痛快!”', 'expression': '愤怒', 'mood': '愤慨'}, {'role': '方老魔', 'dialogue': '你不要妄图反抗了,今日我们正道各大派联合起来,就是要踏破你的魔窟。这里早已经布下天罗地网,这次你必定身首异处!', 'expression': '警告', 'mood': '平静'}, {'role': '方源', 'dialogue': '魔头,三百年前你侮辱了我,夺走了我的清白之身,杀光我全家,诛了我的九族。从那刻起,我恨不得吃你肉,喝你的血!今天,我要让你生不如死!', 'expression': '仇恨', 'mood': '愤怒'}, {'role': '魔头', 'dialogue': '……', 'expression': '平静'}, {'role': '方源', 'dialogue': '', 'expression': '平静'}]\n","[{'role': '方源', 'dialogue': '第一节:纵身亡魔心仍不悔 “方源,乖乖地交出春秋蝉,我给你个痛快!”', 'expression': '愤怒', 'mood': '愤慨'}, {'role': '方老魔', 'dialogue': '你不要妄图反抗了,今日我们正道各大派联合起来,就是要踏破你的魔窟。这里早已经布下天罗地网,这次你必定身首异处!', 'expression': '警告', 'mood': '平静'}, {'role': '方源', 'dialogue': '魔头,三百年前你侮辱了我,夺走了我的清白之身,杀光我全家,诛了我的九族。从那刻起,我恨不得吃你肉,喝你的血!今天,我要让你生不如死!', 'expression': '仇恨', 'mood': '愤怒'}, {'role': '魔头', 'dialogue': '……', 'expression': '平静'}, {'role': '方源', 'dialogue': '', 'expression': '平静'}]\n","第 1 次尝试完成。\n"]}],"source":["import csv\n","content = open('guzhenren.txt','r',encoding='utf-8') #小说路径\n","example_text = content.read()\n","output = []\n","def 对话集(content,example_text):\n","    # 使用示例\n","    paragraphs = split_text_into_paragraphs(example_text)\n","    for i, paragraph in enumerate(paragraphs):\n","        print(f'Paragraph {i + 1}:\\n{paragraph}\\n')\n","        max_attempts = 3  # 最大尝试次数\n","        current_attempt = 1\n","        current_attempt2 = 1\n","        string = []\n","        while current_attempt < max_attempts:\n","            try:\n","                response,history = model.chat(tokenizer, paragraph.replace('\\u3000','').replace('\\n','').replace(',','，').replace(\"''\",'’').replace('''\"''','“'),history = examples)\n","                string.append(response)\n","                print(response)\n","                print(eval(response))\n","            except Exception as e:\n","                print(e)\n","            else:\n","                break\n","            finally:\n","                print(f\"第 {current_attempt} 次尝试完成。\")\n","                current_attempt += 1\n","                continue\n","            print(string)\n","        while (current_attempt2 < max_attempts) and (len(string) ==2):\n","            try:\n","                response1,history1 = model.chat(tokenizer, string,history=edit)\n","                print(eval(response1))\n","            except Exception as e:\n","                print(e)\n","            else:\n","                break\n","            finally:\n","                print(f\"修改完成。\")\n","                current_attempt2 += 1\n","                continue\n","        try:\n","            output.append((paragraph.replace('\\u3000','').replace('\\n','').replace(',','，').replace(\"''\",'’').replace('''\"''','“'),eval(response1)))\n","            file = open('text.txt', 'w', encoding='utf-8')\n","            with open('text.csv', 'w', encoding='utf-8', newline='') as file:\n","                writer = csv.writer(file)\n","                writer.writerow(['content', 'summary'])\n","                writer.writerows(output)\n","        except:\n","            try:\n","                output.append((paragraph.replace('\\u3000','').replace('\\n','').replace(',','，').replace(\"''\",'’').replace('''\"''','“'),eval(response)))\n","#                 file = open('text.txt', 'w', encoding='utf-8')\n","                with open('text.csv', 'w', encoding='utf-8', newline='') as file:\n","                    writer = csv.writer(file)\n","                    writer.writerow(['content', 'summary'])\n","                    writer.writerows(output)\n","            except:\n","                continue\n","            \n","    return output\n","#     print(response)\n","print(对话集(content,example_text))"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4092081,"sourceId":7099197,"sourceType":"datasetVersion"},{"datasetId":4105987,"sourceId":7119173,"sourceType":"datasetVersion"},{"modelInstanceId":3480,"sourceId":4690,"sourceType":"modelInstanceVersion"}],"dockerImageVersionId":30588,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":4}
