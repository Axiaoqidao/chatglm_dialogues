# 项目文档: 对话集提取器

## 1. 项目概述
对话集提取器是一个基于chatglm模型的工具，用于从文本中提取对话集。该工具可以帮助用户从小说、剧本等文本中自动提取出对话，以便进行分析、标注或其他应用。

## 2. 安装和依赖项
为了使用对话集提取器，您需要进行以下准备工作：

### 2.1 安装Python和相关依赖项
确保您的计算机上已经安装了Python，并且具备以下依赖项：
- transformers库：用于加载chatglm模型和进行对话集提取。

您可以使用以下命令安装transformers库：
```
pip install transformers==4.33.2
```

### 2.2 下载chatglm模型
chatglm模型是由清华大学开源的一个用于对话集提取的预训练模型。请注意，chatglm模型的使用受到Model License的限制。根据该许可证，ChatGLM-6B模型的权重对学术研究完全开放，但在其他用途下使用该模型权重可能受到限制。在将项目开源之前，请确保您已经了解并遵守Model License的规定。

您可以从清华大学的GitHub页面下载chatglm模型，并将其保存在本地。

## 3. 使用方法
以下是使用对话集提取器的基本步骤：

### 3.1 准备输入文本
将待提取对话集的文本保存为.txt格式，确保文本内容清晰可读。您可以从小说、剧本等来源获取文本。本项目以《蛊真人》为例

### 3.2 运行代码
使用您喜欢的Python开发环境（如Jupyter Notebook、PyCharm等），打开提供的代码文件。在代码中，您需要进行以下设置：
- 指定chatglm模型的路径：将chatglm模型的路径替换为您下载的chatglm模型的路径。
- 指定输入文本文件的路径：将输入文本文件的路径替换为您准备的文本文件的路径。

运行代码，等待对话集提取完成。提取的对话集将保存在输出文件中。

### 3.3 结果输出
对话集提取器将提取的对话集保存为.csv文件，包含两列：content和summary。
- content列包含原始文本中的段落。
- summary列包含从段落中提取出的对话集。

## 4. 示例和演示
为了帮助您更好地理解对话集提取器的使用，我们提供了一些示例段落。您可以将这些段落作为输入，运行代码并观察输出结果。

示例还演示了如何使用chatglm模型提取对话集，并对输出结果进行修改和调整。您可以参考这些示例来了解如何根据需要对提取的对话集进行编辑和修改。

## 5. 注意事项
在使用对话集提取器时，请注意以下事项：
- chatglm模型的提取结果可能需要多次尝试才能成功。在代码中设置了最大尝试次数，如果超过次数仍未成功提取对话集，则可能需要手动调整模型参数或输入文本。
- 在使用提取结果时，请注意对话集的准确性和完整性。由于chatglm模型的限制，提取结果可能需要手动修改和调整，以获得更准确的对话集。

## 6. 许可证信息
对话集提取器是基于chatglm模型开发的，chatglm模型的代码遵循Apache-2.0许可证。ChatGLM-6B模型的权重使用受到Model License的限制。在将项目开源之前，请确保您已经了解并遵守Model License的规定。

## 7. 参考和致谢
- 清华大学开源的chatglm模型：[链接](https://github.com/THUNLP-MT/Chat)
- Extract Dialogue：[链接](https://github.com/KMnO4-zx/extract-dialogue)
